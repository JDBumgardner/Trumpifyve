{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trumpifyve Training Data Generation",
      "provenance": [],
      "collapsed_sections": [
        "NHc9FmKauNeg"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko3xU_jx3Law",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JDBumgardner/Trumpifyve/Trumpifyve_Training_Data_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHc9FmKauNeg",
        "colab_type": "text"
      },
      "source": [
        "# Copyright 2020 Jacob Bumgardner and Jeremy Salwen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXG0x18kuFgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2020 Jacob Bumgardner and Jeremy Salwen\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBW2VLzyu6SC",
        "colab_type": "text"
      },
      "source": [
        "#Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72GGTzSHu-l0",
        "colab_type": "text"
      },
      "source": [
        "Github: https://github.com/JDBumgardner/Trumpifyve\n",
        "\n",
        "In this notebook we normalize the samples of phrases from Donald Trump's 2016 presidential campaign by passing these phrases through a pair of pretrained NMT translation models. In our case we translate from english to german and back using two models from the fairseq repository. These could replaced with any sequence of translation models that translate from english to english. The intent is to preserve the meaning of the text samples while removing the characteristic style in order to generate training data for the T5 model. The translation models will at times strip leading and trailing sentences from the base phrases, this is unintended behavior, but has the consequence that the model with addend characteristic phrases of the style target. \n",
        "\n",
        "The output files will be written to your google drive at /trump_pairs and will be read by the colab Trumpifyve Train.\n",
        "\n",
        "Next Colab: [Trumpifyve Train](\"https://colab.research.google.com/github/JDBumgardner/Trumpifyve/Trumpifyve_Train.ipynb\")  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XUrcl0MtYWp",
        "colab_type": "text"
      },
      "source": [
        "#Project start"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H_u7PMitnp4",
        "colab_type": "text"
      },
      "source": [
        "We are loading the requirements and dependencies and mounting the drive where we will be saving our training pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AB27-BVubGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sacremoses subword_nmt fastbpe\n",
        "import torch, numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os.path\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tfp2G9toYrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount ('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6LvxWdLoWRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/unendin/Trump_Campaign_Corpus.git \"/content/drive/My Drive/campaign_corpus\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUXLZS65rj8U",
        "colab_type": "text"
      },
      "source": [
        "#Load the NMT models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjDA4thGnKAm",
        "colab_type": "text"
      },
      "source": [
        "Here we load the translation models, one from English to German (transformer.wmt16.en-de) and one from German back to English (transformer.wmt19.de-en.single_model). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ7CzmlkrMha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt16.en-de', tokenizer='moses', bpe='subword_nmt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKFnMIYBnEuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "de2en = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.de-en.single_model', tokenizer='moses', bpe='fastbpe')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUrTdmLb1wzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(input):\n",
        "  return de2en.translate(en2de.translate(input, beam=1), beam=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbv6ih8ieBIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en2de.eval()\n",
        "de2en.eval()\n",
        "en2de.cuda()\n",
        "de2en.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndsFDt9QoltI",
        "colab_type": "text"
      },
      "source": [
        "#Load the corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr6cE7UTrgoX",
        "colab_type": "text"
      },
      "source": [
        "Loads and filters campaign corpus for spoken language and splits into individual samples. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f457U5TMg1j8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/campaign_corpus/trump_campaign_corpus.json') as f:\n",
        "  campaign_corpus=json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnZWDOGhiBVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trump_lines = []\n",
        "\n",
        "for item in campaign_corpus:\n",
        "    if item['is_as_spoken'] is True:\n",
        "        turns = item[\"doc\"]\n",
        "        if type(turns) is not list:\n",
        "            turns = [turns]\n",
        "        for turn in turns:\n",
        "            if turn[\"person\"] == 'Donald Trump':\n",
        "                samples = turn[\"p\"]\n",
        "                if type(samples) is not list:\n",
        "                    samples = [samples]\n",
        "                for sample in samples:\n",
        "                    if type(sample) is not str:\n",
        "                        continue\n",
        "                    trump_lines.append(sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPMtSpPvrvwY",
        "colab_type": "text"
      },
      "source": [
        "#Write to file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEQabsQ0qvmz",
        "colab_type": "text"
      },
      "source": [
        "Write out trump pairs to .json files in chunks of 128 pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhFd5ef-ix77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnlumlXd3KJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir '/content/drive/My Drive/trump_pairs'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf4rZq0XkgGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=128\n",
        "trump_pairs = []\n",
        "for i, chunk in enumerate(chunks(trump_lines,batch_size)):\n",
        "  path = '/content/drive/My Drive/trump_pairs/{}.json'.format(i)\n",
        "  if os.path.exists(path):\n",
        "    continue\n",
        "  else:\n",
        "    current_batch_pair = list(zip(chunk, normalize(chunk)))\n",
        "    trump_pairs += current_batch_pair\n",
        "    with open(path, \"w\") as f:\n",
        "      json.dump(current_batch_pair,f)\n",
        "    print(\"\\r\", i, end=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}